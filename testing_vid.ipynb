{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import imageio\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/46hc8zqn0l9_kwvskdqj7z8h0000gn/T/ipykernel_16695/3130545117.py:14: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  mag *= 255.0/np.max(mag) #normalize\n",
      "/var/folders/sl/46hc8zqn0l9_kwvskdqj7z8h0000gn/T/ipykernel_16695/3130545117.py:14: RuntimeWarning: invalid value encountered in multiply\n",
      "  mag *= 255.0/np.max(mag) #normalize\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sl/46hc8zqn0l9_kwvskdqj7z8h0000gn/T/ipykernel_16695/3130545117.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"canny edge detection\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture(0)\n",
    " \n",
    "# Infinite while loop to treat stack of image as video\n",
    "while True:\n",
    "\n",
    "    #sobel operator\n",
    "    # Reading frame(image) from video\n",
    "    check, frame = video.read()\n",
    "    im = frame.astype('int32')\n",
    "    # im = frame.astype('int32')\n",
    "    dx = ndimage.sobel(im, 0) # horizontal deriv\n",
    "    dy = ndimage.sobel(im, 1) # vertical deriv\n",
    "    mag = np.hypot(dx, dy) # magnitude\n",
    "    mag *= 255.0/np.max(mag) #normalize\n",
    "\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    threshold = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY)[1]\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "    dilate = cv2.morphologyEx(threshold, cv2.MORPH_DILATE, kernel)\n",
    "\n",
    "    diff = cv2.absdiff(dilate, threshold)   \n",
    "    # edges = 255-diff\n",
    "            \n",
    "    # cv2.Canny(frame_webcam, 100, 110, edges=outframe)\n",
    "    img2 = cv2.Canny(frame, 100, 110)\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow(\"normal frame\", frame)\n",
    "    cv2.imshow(\"edge detection sobel\", mag)\n",
    "    cv2.imshow(\"morphological edge out\", diff)\n",
    "    cv2.imshow(\"canny edge detection\", img2)\n",
    "   \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video = cv2.VideoCapture(0)\n",
    " \n",
    "# # Infinite while loop to treat stack of image as video\n",
    "# while True:\n",
    "#     # Reading frame(image) from video\n",
    "#     check, frame = video.read()\n",
    "\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#     threshold = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY)[1]\n",
    "#     kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "#     dilate = cv2.morphologyEx(threshold, cv2.MORPH_DILATE, kernel)\n",
    "\n",
    "#     diff = cv2.absdiff(dilate, threshold)   \n",
    "#     # edges = 255-diff\n",
    "            \n",
    "#     # cv2.Canny(frame_webcam, 100, 110, edges=outframe)\n",
    "#     cv2.imshow(\"canny edge detection\", diff)\n",
    "#     cv2.imshow(\"normal frame\", frame)\n",
    "#     key = cv2.waitKey(1)\n",
    "#     if key == ord('q'):\n",
    "#         break\n",
    "# video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sl/46hc8zqn0l9_kwvskdqj7z8h0000gn/T/ipykernel_16635/705543344.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m                             \u001b[0;34m(\u001b[0m\u001b[0mhorizontal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgray_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                             \u001b[0;34m(\u001b[0m\u001b[0mhorizontal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgray_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                             \u001b[0;34m(\u001b[0m\u001b[0mhorizontal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgray_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                             \u001b[0;34m(\u001b[0m\u001b[0mhorizontal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgray_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                             \u001b[0;34m(\u001b[0m\u001b[0mhorizontal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgray_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# video = cv2.VideoCapture(0)\n",
    " \n",
    "# # Infinite while loop to treat stack of image as video\n",
    "# while True:\n",
    "#     check, frame = video.read()\n",
    "\n",
    "#     im = frame\n",
    "    \n",
    "#     gray_img = np.round(0.299 * im[:, :, 0] +\n",
    "#                         0.587 * im[:, :, 1] +\n",
    "#                         0.114 * im[:, :, 2]).astype(np.uint8)\n",
    "\n",
    "#     # Sobel Operator\n",
    "#     h, w = gray_img.shape\n",
    "#     # define filters\n",
    "#     horizontal = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])  # s2\n",
    "#     vertical = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])  # s1\n",
    "\n",
    "#     # define images with 0s\n",
    "#     newhorizontalImage = np.zeros((h, w))\n",
    "#     newverticalImage = np.zeros((h, w))\n",
    "#     newgradientImage_sobel = np.zeros((h, w))\n",
    "\n",
    "#     # offset by 1\n",
    "#     for i in range(1, h - 1):\n",
    "#         for j in range(1, w - 1):\n",
    "#             horizontalGrad = (horizontal[0, 0] * gray_img[i - 1, j - 1]) + \\\n",
    "#                             (horizontal[0, 1] * gray_img[i - 1, j]) + \\\n",
    "#                             (horizontal[0, 2] * gray_img[i - 1, j + 1]) + \\\n",
    "#                             (horizontal[1, 0] * gray_img[i, j - 1]) + \\\n",
    "#                             (horizontal[1, 1] * gray_img[i, j]) + \\\n",
    "#                             (horizontal[1, 2] * gray_img[i, j + 1]) + \\\n",
    "#                             (horizontal[2, 0] * gray_img[i + 1, j - 1]) + \\\n",
    "#                             (horizontal[2, 1] * gray_img[i + 1, j]) + \\\n",
    "#                             (horizontal[2, 2] * gray_img[i + 1, j + 1])\n",
    "\n",
    "#             newhorizontalImage[i - 1, j - 1] = abs(horizontalGrad)\n",
    "\n",
    "#             verticalGrad = (vertical[0, 0] * gray_img[i - 1, j - 1]) + \\\n",
    "#                         (vertical[0, 1] * gray_img[i - 1, j]) + \\\n",
    "#                         (vertical[0, 2] * gray_img[i - 1, j + 1]) + \\\n",
    "#                         (vertical[1, 0] * gray_img[i, j - 1]) + \\\n",
    "#                         (vertical[1, 1] * gray_img[i, j]) + \\\n",
    "#                         (vertical[1, 2] * gray_img[i, j + 1]) + \\\n",
    "#                         (vertical[2, 0] * gray_img[i + 1, j - 1]) + \\\n",
    "#                         (vertical[2, 1] * gray_img[i + 1, j]) + \\\n",
    "#                         (vertical[2, 2] * gray_img[i + 1, j + 1])\n",
    "\n",
    "#             newverticalImage[i - 1, j - 1] = abs(verticalGrad)\n",
    "\n",
    "#             # Edge Magnitude\n",
    "#             mag = np.sqrt(pow(horizontalGrad, 2.0) + pow(verticalGrad, 2.0))\n",
    "#             newgradientImage_sobel[i - 1, j - 1] = mag\n",
    "\n",
    "#     cv2.imshow(\"edge detection sobel\", newgradientImage_sobel)\n",
    "#     cv2.imshow(\"normal frame\", frame)\n",
    "#     key = cv2.waitKey(1)\n",
    "#     if key == ord('q'):\n",
    "#         break\n",
    "# video.release()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c363bd452b4cd960c3544f6b5b319cd180a5fb23ba0f180b40c1c18a7f15ae61"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
